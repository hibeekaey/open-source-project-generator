# {{.Name}} Deployment Guide

This guide covers deploying {{.Name}} to various environments, from development to production.

## ðŸ“‹ Table of Contents

- [Overview](#overview)
- [Prerequisites](#prerequisites)
- [Environment Setup](#environment-setup)
- [Local Development](#local-development)
{{if .Components.Infrastructure.Docker}}- [Docker Deployment](#docker-deployment){{end}}
{{if .Components.Infrastructure.Kubernetes}}- [Kubernetes Deployment](#kubernetes-deployment){{end}}
{{if .Components.Infrastructure.Terraform}}- [Infrastructure as Code](#infrastructure-as-code){{end}}
- [Cloud Deployments](#cloud-deployments)
- [CI/CD Pipeline](#cicd-pipeline)
- [Monitoring & Logging](#monitoring--logging)
- [Security Considerations](#security-considerations)
- [Troubleshooting](#troubleshooting)

## Overview

{{.Name}} is designed for flexible deployment across various environments:

### Deployment Options

- **Local Development**: Quick setup for development
{{if .Components.Infrastructure.Docker}}- **Docker**: Containerized deployment for consistency{{end}}
{{if .Components.Infrastructure.Kubernetes}}- **Kubernetes**: Scalable orchestration for production{{end}}
- **Cloud Platforms**: AWS, GCP, Azure support
{{if .Components.Infrastructure.Terraform}}- **Infrastructure as Code**: Terraform for reproducible infrastructure{{end}}

### Architecture Components

{{if .Components.Frontend.MainApp}}- **Frontend Applications**: Next.js applications{{end}}
{{if .Components.Backend.API}}- **Backend API**: Go-based REST API server{{end}}
{{if .Components.Mobile.Android}}- **Android App**: Native mobile application{{end}}
{{if .Components.Mobile.iOS}}- **iOS App**: Native mobile application{{end}}
- **Database**: PostgreSQL for data persistence
- **Cache**: Redis for session and data caching
- **File Storage**: S3-compatible object storage

## Prerequisites

### Required Tools

- **Git**: Version control
- **Make**: Build automation
{{if .Components.Frontend.MainApp}}- **Node.js**: {{.Versions.Node}} or later
- **npm**: 10.0.0 or later (or yarn equivalent){{end}}
{{if .Components.Backend.API}}- **Go**: {{.Versions.Go}} or later{{end}}
{{if .Components.Infrastructure.Docker}}- **Docker**: 20.10+ with Docker Compose v2{{end}}
{{if .Components.Infrastructure.Kubernetes}}- **kubectl**: Kubernetes CLI
- **Helm**: 3.0+ for package management{{end}}
{{if .Components.Infrastructure.Terraform}}- **Terraform**: 1.0+ for infrastructure{{end}}

### System Requirements

#### Minimum (Development)
- **CPU**: 2 cores
- **RAM**: 4GB
- **Storage**: 10GB free space
- **OS**: Linux, macOS, or Windows with WSL2

#### Recommended (Production)
- **CPU**: 4+ cores
- **RAM**: 8GB+
- **Storage**: 50GB+ SSD
- **Network**: Stable internet connection

## Environment Setup

### Environment Variables

Create environment files for each component:

#### Root Environment (`.env.local`)
```bash
# Application Configuration
APP_NAME={{.Name}}
APP_ENV=development
APP_DEBUG=false // SECURITY FIX: Disabled debug info (use env var for dev)
APP_URL=http://localhost:3000

# Database Configuration
DATABASE_URL=postgresql://{{.Name}}_user:password@localhost:5432/{{.Name}}_dev
DATABASE_POOL_SIZE=10

# Redis Configuration
REDIS_URL=redis://localhost:6379/0
REDIS_POOL_SIZE=10

# Security
JWT_SECRET=your-super-secret-jwt-key-change-in-production
ENCRYPTION_KEY=your-32-character-encryption-key

# External Services
{{if .Components.Backend.API}}API_BASE_URL=http://localhost:8080{{end}}
{{if .Components.Frontend.MainApp}}FRONTEND_URL=http://localhost:3000{{end}}

# File Storage
STORAGE_DRIVER=local
AWS_ACCESS_KEY_ID=your-aws-access-key
AWS_SECRET_ACCESS_KEY=your-aws-secret-key
AWS_DEFAULT_REGION=us-east-1
AWS_BUCKET={{.Name}}-storage

# Email Configuration
MAIL_DRIVER=smtp
MAIL_HOST=smtp.mailtrap.io
MAIL_PORT=2525
MAIL_USERNAME=your-username
MAIL_PASSWORD=your-password
MAIL_FROM_ADDRESS=noreply@{{.Name}}.com
MAIL_FROM_NAME={{.Name}}

# Monitoring
SENTRY_DSN=your-sentry-dsn
LOG_LEVEL=info
```

{{if .Components.Backend.API}}#### Backend Environment (`CommonServer/.env`)
```bash
# Server Configuration
PORT=8080
HOST=0.0.0.0
GIN_MODE=debug

# Database
DATABASE_URL=postgresql://{{.Name}}_user:password@localhost:5432/{{.Name}}_dev
DATABASE_MAX_CONNECTIONS=25
DATABASE_MAX_IDLE_CONNECTIONS=5

# Redis
REDIS_URL=redis://localhost:6379/0
REDIS_PASSWORD=
REDIS_DB=0

# JWT Configuration
JWT_SECRET=your-super-secret-jwt-key
JWT_EXPIRY=3600
JWT_REFRESH_EXPIRY=2592000

# CORS Configuration
CORS_ALLOWED_ORIGINS=http://localhost:3000,http://localhost:3001,http://localhost:3002
CORS_ALLOWED_METHODS=GET,POST,PUT,DELETE,OPTIONS
CORS_ALLOWED_HEADERS=Content-Type,Authorization

# Rate Limiting
RATE_LIMIT_REQUESTS_PER_MINUTE=60
RATE_LIMIT_BURST=10

# File Upload
MAX_UPLOAD_SIZE=10485760
ALLOWED_FILE_TYPES=jpg,jpeg,png,gif,pdf,doc,docx

# External APIs
EXTERNAL_API_KEY=your-external-api-key
EXTERNAL_API_URL=https://api.external-service.com

# Monitoring
ENABLE_METRICS=true
METRICS_PORT=9090
```{{end}}

### Database Setup

#### PostgreSQL Installation

**Using Docker:**
```bash
docker run --name {{.Name}}-postgres \
  -e POSTGRES_DB={{.Name}}_dev \
  -e POSTGRES_USER={{.Name}}_user \
  -e POSTGRES_PASSWORD=password \
  -p 5432:5432 \
  -d postgres:15
```

**Using Package Manager:**
```bash
# Ubuntu/Debian
sudo apt-get install postgresql postgresql-contrib

# macOS
brew install postgresql

# Start service
sudo systemctl start postgresql  # Linux
brew services start postgresql   # macOS
```

#### Database Initialization

```bash
# Create database and user
sudo -u postgres psql
CREATE DATABASE {{.Name}}_dev;
CREATE USER {{.Name}}_user WITH PASSWORD 'password';
GRANT ALL PRIVILEGES ON DATABASE {{.Name}}_dev TO {{.Name}}_user;
\q

# Run migrations
{{if .Components.Backend.API}}cd CommonServer
make db-migrate{{end}}
```

### Redis Setup

#### Redis Installation

**Using Docker:**
```bash
docker run --name {{.Name}}-redis \
  -p 6379:6379 \
  -d redis:7-alpine
```

**Using Package Manager:**
```bash
# Ubuntu/Debian
sudo apt-get install redis-server

# macOS
brew install redis

# Start service
sudo systemctl start redis-server  # Linux
brew services start redis          # macOS
```

## Local Development

### Quick Start

```bash
# Clone repository
git clone https://github.com/{{.Organization}}/{{.Name}}.git
cd {{.Name}}

# Setup environment
make setup

# Start all services
make dev
```

### Manual Setup

#### 1. Install Dependencies

{{if .Components.Frontend.MainApp}}```bash
# Frontend dependencies
{{if .Components.Frontend.MainApp}}cd App && npm install && cd ..{{end}}
{{if .Components.Frontend.Home}}cd Home && npm install && cd ..{{end}}
{{if .Components.Frontend.Admin}}cd Admin && npm install && cd ..{{end}}
```{{end}}

{{if .Components.Backend.API}}```bash
# Backend dependencies
cd CommonServer
go mod download
go mod tidy
cd ..
```{{end}}

#### 2. Database Setup

```bash
# Start database services
{{if .Components.Infrastructure.Docker}}docker-compose up -d postgres redis{{else}}# Start PostgreSQL and Redis services{{end}}

# Run migrations
{{if .Components.Backend.API}}make db-migrate{{end}}

# Seed test data (optional)
{{if .Components.Backend.API}}make db-seed{{end}}
```

#### 3. Start Services

```bash
# Start all services
make dev

# Or start individually
{{if .Components.Frontend.MainApp}}make dev-frontend    # Frontend applications{{end}}
{{if .Components.Backend.API}}make dev-backend     # Backend API{{end}}
```

### Development URLs

{{if .Components.Frontend.MainApp}}- **Main App**: [http://localhost:3000](http://localhost:3000){{end}}
{{if .Components.Frontend.Home}}- **Home Page**: [http://localhost:3001](http://localhost:3001){{end}}
{{if .Components.Frontend.Admin}}- **Admin Dashboard**: [http://localhost:3002](http://localhost:3002){{end}}
{{if .Components.Backend.API}}- **API Server**: [http://localhost:8080](http://localhost:8080)
- **API Docs**: [http://localhost:8080/swagger](http://localhost:8080/swagger){{end}}

{{if .Components.Infrastructure.Docker}}## Docker Deployment

### Development with Docker

```bash
# Build and start all services
make docker-dev

# Or use docker-compose directly
docker-compose -f docker-compose.dev.yml up --build
```

### Production Docker Setup

#### 1. Build Images

```bash
# Build all images
make docker-build

# Build specific services
{{if .Components.Frontend.MainApp}}docker build -t {{.Name}}/frontend -f App/Dockerfile App/{{end}}
{{if .Components.Backend.API}}docker build -t {{.Name}}/backend -f CommonServer/Dockerfile CommonServer/{{end}}
```

#### 2. Production Compose

Create `docker-compose.prod.yml`:

```yaml
version: '3.8'

services:
{{if .Components.Frontend.MainApp}}  frontend:
    image: {{.Name}}/frontend:latest
    ports:
      - "3000:3000"
    environment:
      - NODE_ENV=production
      - NEXT_PUBLIC_API_URL=https://api.{{.Name}}.com
    depends_on:
      - backend
    restart: unless-stopped{{end}}

{{if .Components.Backend.API}}  backend:
    image: {{.Name}}/backend:latest
    ports:
      - "8080:8080"
    environment:
      - GIN_MODE=release
      - DATABASE_URL=postgresql://user:pass@postgres:5432/{{.Name}}_prod
      - REDIS_URL=redis://redis:6379/0
    depends_on:
      - postgres
      - redis
    restart: unless-stopped{{end}}

  postgres:
    image: postgres:15
    environment:
      - POSTGRES_DB={{.Name}}_prod
      - POSTGRES_USER={{.Name}}_user
      - POSTGRES_PASSWORD=${POSTGRES_PASSWORD}
    volumes:
      - postgres_data:/var/lib/postgresql/data
    restart: unless-stopped

  redis:
    image: redis:7-alpine
    volumes:
      - redis_data:/data
    restart: unless-stopped

  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - frontend
      - backend
    restart: unless-stopped

volumes:
  postgres_data:
  redis_data:
```

#### 3. Deploy with Docker

```bash
# Set production environment variables
export POSTGRES_PASSWORD=your-secure-password

# Deploy
docker-compose -f docker-compose.prod.yml up -d

# Check status
docker-compose -f docker-compose.prod.yml ps

# View logs
docker-compose -f docker-compose.prod.yml logs -f
```{{end}}

{{if .Components.Infrastructure.Kubernetes}}## Kubernetes Deployment

### Prerequisites

- Kubernetes cluster (1.20+)
- kubectl configured
- Helm 3.0+
- Ingress controller (nginx, traefik, etc.)

### Namespace Setup

```bash
# Create namespace
kubectl create namespace {{.Name}}

# Set as default
kubectl config set-context --current --namespace={{.Name}}
```

### Using Helm Charts

#### 1. Install with Helm

```bash
# Add Helm repository (if published)
helm repo add {{.Name}} https://charts.{{.Name}}.com
helm repo update

# Install
helm install {{.Name}} {{.Name}}/{{.Name}} \
  --namespace {{.Name}} \
  --create-namespace \
  --values values.prod.yaml
```

#### 2. Manual Deployment

```bash
# Deploy all manifests
kubectl apply -f Deploy/Kubernetes/

# Or deploy individually
kubectl apply -f Deploy/Kubernetes/namespace.yaml
kubectl apply -f Deploy/Kubernetes/configmap.yaml
kubectl apply -f Deploy/Kubernetes/secret.yaml
kubectl apply -f Deploy/Kubernetes/deployments/
kubectl apply -f Deploy/Kubernetes/services.yaml
kubectl apply -f Deploy/Kubernetes/ingress.yaml
```

### Configuration

#### Values for Production (`values.prod.yaml`)

```yaml
# Global configuration
global:
  imageRegistry: "your-registry.com"
  imageTag: "v1.0.0"
  storageClass: "fast-ssd"

# Frontend configuration
{{if .Components.Frontend.MainApp}}frontend:
  enabled: true
  replicaCount: 3
  image:
    repository: {{.Name}}/frontend
    tag: "v1.0.0"
  service:
    type: ClusterIP
    port: 3000
  resources:
    requests:
      memory: "256Mi"
      cpu: "250m"
    limits:
      memory: "512Mi"
      cpu: "500m"
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 10
    targetCPUUtilizationPercentage: 70{{end}}

# Backend configuration
{{if .Components.Backend.API}}backend:
  enabled: true
  replicaCount: 3
  image:
    repository: {{.Name}}/backend
    tag: "v1.0.0"
  service:
    type: ClusterIP
    port: 8080
  resources:
    requests:
      memory: "512Mi"
      cpu: "500m"
    limits:
      memory: "1Gi"
      cpu: "1000m"
  autoscaling:
    enabled: true
    minReplicas: 2
    maxReplicas: 20
    targetCPUUtilizationPercentage: 70{{end}}

# Database configuration
postgresql:
  enabled: true
  auth:
    postgresPassword: "your-secure-password"
    database: "{{.Name}}_prod"
  primary:
    persistence:
      enabled: true
      size: 100Gi
      storageClass: "fast-ssd"
  resources:
    requests:
      memory: "1Gi"
      cpu: "500m"
    limits:
      memory: "2Gi"
      cpu: "1000m"

# Redis configuration
redis:
  enabled: true
  auth:
    enabled: true
    password: "your-redis-password"
  master:
    persistence:
      enabled: true
      size: 10Gi
  resources:
    requests:
      memory: "256Mi"
      cpu: "250m"
    limits:
      memory: "512Mi"
      cpu: "500m"

# Ingress configuration
ingress:
  enabled: true
  className: "nginx"
  annotations:
    cert-manager.io/cluster-issuer: "letsencrypt-prod"
    nginx.ingress.kubernetes.io/ssl-redirect: "true"
  hosts:
    - host: {{.Name}}.com
      paths:
        - path: /
          pathType: Prefix
          service: frontend
    - host: api.{{.Name}}.com
      paths:
        - path: /
          pathType: Prefix
          service: backend
  tls:
    - secretName: {{.Name}}-tls
      hosts:
        - {{.Name}}.com
        - api.{{.Name}}.com

# Monitoring
monitoring:
  enabled: true
  prometheus:
    enabled: true
  grafana:
    enabled: true
```

### Deployment Commands

```bash
# Deploy to staging
helm upgrade --install {{.Name}}-staging {{.Name}}/{{.Name}} \
  --namespace {{.Name}}-staging \
  --create-namespace \
  --values values.staging.yaml

# Deploy to production
helm upgrade --install {{.Name}}-prod {{.Name}}/{{.Name}} \
  --namespace {{.Name}}-prod \
  --create-namespace \
  --values values.prod.yaml

# Check deployment status
kubectl get pods -n {{.Name}}-prod
kubectl get services -n {{.Name}}-prod
kubectl get ingress -n {{.Name}}-prod

# View logs
kubectl logs -f deployment/{{.Name}}-backend -n {{.Name}}-prod
```{{end}}

{{if .Components.Infrastructure.Terraform}}## Infrastructure as Code

### Terraform Setup

#### 1. Initialize Terraform

```bash
cd Deploy/Terraform

# Initialize
terraform init

# Select workspace
terraform workspace select prod
# or create new workspace
terraform workspace new prod
```

#### 2. Configure Variables

Create `terraform.tfvars`:

```hcl
# Project configuration
project_name = "{{.Name}}"
environment = "production"
region = "us-east-1"

# Network configuration
vpc_cidr = "10.0.0.0/16"
availability_zones = ["us-east-1a", "us-east-1b", "us-east-1c"]

# Database configuration
db_instance_class = "db.t3.medium"
db_allocated_storage = 100
db_backup_retention_period = 7
db_multi_az = true

# Application configuration
app_instance_type = "t3.medium"
app_min_size = 2
app_max_size = 10
app_desired_capacity = 3

# Domain configuration
domain_name = "{{.Name}}.com"
api_domain_name = "api.{{.Name}}.com"

# SSL certificate
ssl_certificate_arn = "arn:aws:acm:us-east-1:123456789012:certificate/12345678-1234-1234-1234-123456789012"

# Monitoring
enable_monitoring = true
log_retention_days = 30

# Backup configuration
backup_schedule = "cron(0 2 * * ? *)"
backup_retention_days = 30
```

#### 3. Deploy Infrastructure

```bash
# Plan deployment
terraform plan -var-file="terraform.tfvars"

# Apply changes
terraform apply -var-file="terraform.tfvars"

# View outputs
terraform output
```

### Multi-Environment Setup

#### Directory Structure

```
Deploy/Terraform/
â”œâ”€â”€ environments/
â”‚   â”œâ”€â”€ dev/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â””â”€â”€ terraform.tfvars
â”‚   â”œâ”€â”€ staging/
â”‚   â”‚   â”œâ”€â”€ main.tf
â”‚   â”‚   â””â”€â”€ terraform.tfvars
â”‚   â””â”€â”€ prod/
â”‚       â”œâ”€â”€ main.tf
â”‚       â””â”€â”€ terraform.tfvars
â”œâ”€â”€ modules/
â”‚   â”œâ”€â”€ vpc/
â”‚   â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ application/
â”‚   â””â”€â”€ monitoring/
â”œâ”€â”€ main.tf
â”œâ”€â”€ variables.tf
â””â”€â”€ outputs.tf
```

#### Environment-Specific Deployment

```bash
# Development
cd environments/dev
terraform init
terraform apply

# Staging
cd ../staging
terraform init
terraform apply

# Production
cd ../prod
terraform init
terraform apply
```{{end}}

## Cloud Deployments

### AWS Deployment

#### Using AWS App Runner

```bash
# Create apprunner.yaml
cat > apprunner.yaml << EOF
version: 1.0
runtime: nodejs20
build:
  commands:
    build:
      - npm ci
      - npm run build
run:
  runtime-version: 20
  command: npm start
  network:
    port: 3000
    env: PORT
  env:
    - name: NODE_ENV
      value: production
EOF

# Deploy via AWS CLI
aws apprunner create-service \
  --service-name {{.Name}} \
  --source-configuration '{
    "ImageRepository": {
      "ImageIdentifier": "your-account.dkr.ecr.region.amazonaws.com/{{.Name}}:latest",
      "ImageConfiguration": {
        "Port": "3000"
      },
      "ImageRepositoryType": "ECR"
    },
    "AutoDeploymentsEnabled": true
  }'
```

#### Using Elastic Beanstalk

```bash
# Install EB CLI
pip install awsebcli

# Initialize application
eb init {{.Name}} --region us-east-1

# Create environment
eb create {{.Name}}-prod

# Deploy
eb deploy
```

### Google Cloud Platform

#### Using Cloud Run

```bash
# Build and push image
gcloud builds submit --tag gcr.io/PROJECT_ID/{{.Name}}

# Deploy to Cloud Run
gcloud run deploy {{.Name}} \
  --image gcr.io/PROJECT_ID/{{.Name}} \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated
```

#### Using App Engine

```yaml
# app.yaml
runtime: nodejs20

env_variables:
  NODE_ENV: production
  DATABASE_URL: postgresql://user:pass@/{{.Name}}?host=/cloudsql/PROJECT_ID:REGION:INSTANCE_ID

automatic_scaling:
  min_instances: 1
  max_instances: 10
```

```bash
# Deploy
gcloud app deploy
```

### Microsoft Azure

#### Using Container Instances

```bash
# Create resource group
az group create --name {{.Name}}-rg --location eastus

# Deploy container
az container create \
  --resource-group {{.Name}}-rg \
  --name {{.Name}} \
  --image your-registry.azurecr.io/{{.Name}}:latest \
  --dns-name-label {{.Name}} \
  --ports 3000
```

#### Using App Service

```bash
# Create App Service plan
az appservice plan create \
  --name {{.Name}}-plan \
  --resource-group {{.Name}}-rg \
  --sku B1 \
  --is-linux

# Create web app
az webapp create \
  --resource-group {{.Name}}-rg \
  --plan {{.Name}}-plan \
  --name {{.Name}} \
  --deployment-container-image-name your-registry.azurecr.io/{{.Name}}:latest
```

## CI/CD Pipeline

### GitHub Actions

The project includes comprehensive CI/CD workflows:

#### Workflow Files

- `.github/workflows/ci-frontend.yml` - Frontend testing and building
- `.github/workflows/ci-backend.yml` - Backend testing and building
- `.github/workflows/security-scan.yml` - Security scanning
- `.github/workflows/deploy-staging.yml` - Staging deployment
- `.github/workflows/deploy-production.yml` - Production deployment

#### Deployment Workflow

```yaml
name: Deploy to Production

on:
  push:
    branches: [main]
  workflow_dispatch:

jobs:
  deploy:
    runs-on: ubuntu-latest
    environment: production
    
    steps:
      - uses: actions/checkout@v4
      
      - name: Configure AWS credentials
        uses: aws-actions/configure-aws-credentials@v4
        with:
          aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
          aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
          aws-region: us-east-1
      
      - name: Deploy to production
        run: |
          make deploy-prod
```

### Required Secrets

Configure these secrets in your repository:

```bash
# AWS credentials
AWS_ACCESS_KEY_ID
AWS_SECRET_ACCESS_KEY

# Database
DATABASE_URL
REDIS_URL

# Application secrets
JWT_SECRET
ENCRYPTION_KEY

# External services
SENTRY_DSN
SENDGRID_API_KEY

# Container registry
DOCKER_REGISTRY_URL
DOCKER_REGISTRY_USERNAME
DOCKER_REGISTRY_PASSWORD
```

## Monitoring & Logging

### Application Monitoring

#### Health Checks

{{if .Components.Backend.API}}```bash
# Backend health check
curl http://localhost:8080/health

# Response
{
  "status": "healthy",
  "timestamp": "2024-01-15T10:30:00Z",
  "version": "1.0.0",
  "services": {
    "database": "healthy",
    "redis": "healthy"
  }
}
```{{end}}

{{if .Components.Frontend.MainApp}}```bash
# Frontend health check
curl http://localhost:3000/api/health
```{{end}}

#### Metrics Endpoints

{{if .Components.Backend.API}}- **Prometheus metrics**: `http://localhost:8080/metrics`
- **Application metrics**: `http://localhost:8080/api/v1/metrics`{{end}}

### Logging Configuration

#### Log Levels

- **DEBUG**: Detailed debugging informatioff // SECURITY FIX: Disabled debug info (use env var for dev)
- **INFO**: General information messages
- **WARN**: Warning messages
- **ERROR**: Error messages
- **FATAL**: Fatal error messages

#### Log Format

```json
{
  "timestamp": "2024-01-15T10:30:00Z",
  "level": "INFO",
  "service": "{{.Name}}-backend",
  "message": "User authenticated successfully",
  "user_id": "123e4567-e89b-12d3-a456-426614174000",
  "request_id": "req_123456789",
  "duration_ms": 45
}
```

### Monitoring Stack

#### Prometheus + Grafana

```yaml
# docker-compose.monitoring.yml
version: '3.8'

services:
  prometheus:
    image: prom/prometheus:latest
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
      - prometheus_data:/prometheus

  grafana:
    image: grafana/grafana:latest
    ports:
      - "3001:3000"
    environment:
      - GF_SECURITY_ADMIN_PASSWORD=admin
    volumes:
      - grafana_data:/var/lib/grafana
      - ./grafana/dashboards:/etc/grafana/provisioning/dashboards
      - ./grafana/datasources:/etc/grafana/provisioning/datasources

volumes:
  prometheus_data:
  grafana_data:
```

#### ELK Stack

```yaml
# docker-compose.logging.yml
version: '3.8'

services:
  elasticsearch:
    image: docker.elastic.co/elasticsearch/elasticsearch:8.5.0
    environment:
      - discovery.type=single-node
      - xpack.security.enabled=false
    ports:
      - "9200:9200"
    volumes:
      - elasticsearch_data:/usr/share/elasticsearch/data

  logstash:
    image: docker.elastic.co/logstash/logstash:8.5.0
    ports:
      - "5044:5044"
    volumes:
      - ./logstash.conf:/usr/share/logstash/pipeline/logstash.conf

  kibana:
    image: docker.elastic.co/kibana/kibana:8.5.0
    ports:
      - "5601:5601"
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200

volumes:
  elasticsearch_data:
```

## Security Considerations

### SSL/TLS Configuration

#### Let's Encrypt with Certbot

```bash
# Install certbot
sudo apt-get install certbot python3-certbot-nginx

# Obtain certificate
sudo certbot --nginx -d {{.Name}}.com -d api.{{.Name}}.com

# Auto-renewal
sudo crontab -e
# Add: 0 12 * * * /usr/bin/certbot renew --quiet
```

#### Manual SSL Setup

```nginx
# nginx SSL configuration
server {
    listen 443 ssl http2;
    server_name {{.Name}}.com;

    ssl_certificate /etc/ssl/certs/{{.Name}}.com.crt;
    ssl_certificate_key /etc/ssl/private/{{.Name}}.com.key;
    
    ssl_protocols TLSv1.2 TLSv1.3;
    ssl_ciphers ECDHE-RSA-AES256-GCM-SHA512:DHE-RSA-AES256-GCM-SHA512;
    ssl_prefer_server_ciphers off;
    
    add_header Strict-Transport-Security "max-age=63072000" always;
    add_header X-Frame-Options DENY;
    add_header X-Content-Type-Options nosniff;
}
```

### Environment Security

#### Secrets Management

```bash
# Using AWS Secrets Manager
aws secretsmanager create-secret \
  --name {{.Name}}/prod/database \
  --description "Database credentials for {{.Name}}" \
  --secret-string '{"username":"{{.Name}}_user","password":"secure-password"}'

# Using Kubernetes secrets
kubectl create secret generic {{.Name}}-secrets \
  --from-literal=database-url="postgresql://user:pass@host:5432/db" \
  --from-literal=jwt-secret="your-jwt-secret"
```

#### Network Security

```bash
# Firewall rules (UFW)
sudo ufw allow ssh
sudo ufw allow 80/tcp
sudo ufw allow 443/tcp
sudo ufw deny 8080/tcp  # Block direct API access
sudo ufw enable

# Docker network isolation
docker network create {{.Name}}-network --driver bridge
```

### Security Scanning

#### Container Scanning

```bash
# Trivy scanning
trivy image {{.Name}}/frontend:latest
trivy image {{.Name}}/backend:latest

# Snyk scanning
snyk container test {{.Name}}/frontend:latest
snyk container test {{.Name}}/backend:latest
```

#### Dependency Scanning

```bash
# Frontend dependencies
{{if .Components.Frontend.MainApp}}cd App && npm audit{{end}}

# Backend dependencies
{{if .Components.Backend.API}}cd CommonServer && go list -json -m all | nancy sleuth{{end}}
```

## Troubleshooting

### Common Issues

#### Service Won't Start

**Symptoms**: Service fails to start or crashes immediately

**Diagnosis**:
```bash
# Check logs
{{if .Components.Infrastructure.Docker}}docker-compose logs service-name{{end}}
{{if .Components.Infrastructure.Kubernetes}}kubectl logs deployment/service-name{{end}}

# Check resource usage
{{if .Components.Infrastructure.Docker}}docker stats{{end}}
{{if .Components.Infrastructure.Kubernetes}}kubectl top pods{{end}}

# Check configuration
{{if .Components.Backend.API}}go run main.go --check-config{{end}}
```

**Solutions**:
1. Verify environment variables are set correctly
2. Check database connectivity
3. Ensure sufficient resources (CPU, memory)
4. Validate configuration files

#### Database Connection Issues

**Symptoms**: "Connection refused" or timeout errors

**Diagnosis**:
```bash
# Test database connectivity
{{if .Components.Backend.API}}psql $DATABASE_URL -c "SELECT 1;"{{end}}

# Check database status
{{if .Components.Infrastructure.Docker}}docker-compose ps postgres{{end}}
{{if .Components.Infrastructure.Kubernetes}}kubectl get pods -l app=postgresql{{end}}

# Check network connectivity
telnet database-host 5432
```

**Solutions**:
1. Verify database is running
2. Check connection string format
3. Validate network connectivity
4. Check firewall rules

#### High Memory Usage

**Symptoms**: Out of memory errors or slow performance

**Diagnosis**:
```bash
# Check memory usage
{{if .Components.Infrastructure.Docker}}docker stats --no-stream{{end}}
{{if .Components.Infrastructure.Kubernetes}}kubectl top pods{{end}}

# Application-specific memory profiling
{{if .Components.Backend.API}}go tool pprof http://localhost:8080/debug/pprof/heap{{end}}
```

**Solutions**:
1. Increase memory limits
2. Optimize application code
3. Enable garbage collection tuning
4. Scale horizontally

#### SSL Certificate Issues

**Symptoms**: SSL/TLS errors or certificate warnings

**Diagnosis**:
```bash
# Check certificate validity
openssl s_client -connect {{.Name}}.com:443 -servername {{.Name}}.com

# Check certificate expiration
echo | openssl s_client -connect {{.Name}}.com:443 2>/dev/null | openssl x509 -noout -dates
```

**Solutions**:
1. Renew expired certificates
2. Verify certificate chain
3. Check domain validation
4. Update certificate configuration

### Performance Optimization

#### Database Optimization

```sql
-- Check slow queries
SELECT query, mean_time, calls 
FROM pg_stat_statements 
ORDER BY mean_time DESC 
LIMIT 10;

-- Add indexes for common queries
CREATE INDEX CONCURRENTLY idx_users_email ON users(email);
CREATE INDEX CONCURRENTLY idx_users_created_at ON users(created_at);
```

#### Application Optimization

{{if .Components.Backend.API}}```go
// Enable Go profiling
import _ "net/http/pprof"

// Add to main function
go func() {
    log.Println(http.ListenAndServe("localhost:6060", nil))
}()
```{{end}}

{{if .Components.Frontend.MainApp}}```javascript
// Next.js optimization
// next.config.js
module.exports = {
  experimental: {
    optimizeCss: true,
    optimizeImages: true,
  },
  compress: true,
  poweredByHeader: false,
}
```{{end}}

### Monitoring Alerts

#### Prometheus Alerting Rules

```yaml
# alerts.yml
groups:
  - name: {{.Name}}.rules
    rules:
      - alert: HighErrorRate
        expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.1
        for: 5m
        labels:
          severity: critical
        annotations:
          summary: "High error rate detected"
          
      - alert: HighMemoryUsage
        expr: (node_memory_MemTotal_bytes - node_memory_MemAvailable_bytes) / node_memory_MemTotal_bytes > 0.9
        for: 5m
        labels:
          severity: warning
        annotations:
          summary: "High memory usage detected"
```

### Backup and Recovery

#### Database Backup

```bash
# Create backup
pg_dump $DATABASE_URL > {{.Name}}_backup_$(date +%Y%m%d_%H%M%S).sql

# Automated backup script
#!/bin/bash
BACKUP_DIR="/backups"
DATE=$(date +%Y%m%d_%H%M%S)
FILENAME="{{.Name}}_backup_$DATE.sql"

pg_dump $DATABASE_URL > "$BACKUP_DIR/$FILENAME"
gzip "$BACKUP_DIR/$FILENAME"

# Keep only last 7 days of backups
find $BACKUP_DIR -name "{{.Name}}_backup_*.sql.gz" -mtime +7 -delete
```

#### Application Data Backup

```bash
# Backup uploaded files
aws s3 sync s3://{{.Name}}-storage /backup/files/

# Backup Redis data
redis-cli --rdb /backup/redis/dump.rdb
```

### Recovery Procedures

#### Database Recovery

```bash
# Restore from backup
psql $DATABASE_URL < {{.Name}}_backup_20240115_120000.sql

# Point-in-time recovery (if using WAL-E or similar)
wal-e backup-fetch /var/lib/postgresql/9.6/main LATEST
```

#### Application Recovery

```bash
# Restore application files
aws s3 sync /backup/files/ s3://{{.Name}}-storage

# Restart services
{{if .Components.Infrastructure.Docker}}docker-compose restart{{end}}
{{if .Components.Infrastructure.Kubernetes}}kubectl rollout restart deployment/{{.Name}}-backend{{end}}
```

---

**Need help with deployment?** Contact our DevOps team at devops@{{.Organization}}.com

*Last updated: {{.CurrentDate}}*